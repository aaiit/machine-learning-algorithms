<!-- 



Compile command : g++ main<>.cpp -o bin/exe<> -llapack -lblas -larmadillo
% git add -A; git commit -m "momentum" ; git push

https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9

costs : typeerror-/problemName-AlgorithmName-nameofdata

todo :  implimenting 10
		draw weight on images
-->


# Perceptron

# Adaline

# Pocket

# Gradient Descent

# Gradient Descent Stochastic

# Momentum

# AdaGrad (todo)

# RMSprop (todo)

# Adadelta (todo)

# Nesterov Accelerated Gradient (NAG) (todo)

# Adam (todo)

# AdaMax (todo)

# Nadam (todo)

# AMSGrad (todo)

## Appendix
![Appendix](algorithms/ok.png)


